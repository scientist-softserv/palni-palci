#!/usr/bin/env ruby

# this script is intented to produce a sample spreadsheet from
# Stanford provided bagit bags that happen to contain MODS files.
# The directory should contain the druid in the form:
#   'base_path/druid_wg827ks1643/**/descMetadata.xml'
#
# Usage example:
#   ./bin/extract_mods_to_spreadsheet ../hyku-bags/ out.csv

base_path = ARGV[0]
output_path = ARGV[1]
unless base_path
  $stderr.puts "Provide a base_path"
  exit(1)
end

unless output_path
  $stderr.puts "Provide an output file name"
  exit(1)
end

puts 'Loading environment...'
require File.expand_path('../../config/environment', __FILE__)
require 'importer'
puts 'Starting import...'

# Assumption: filename will contain the druid.  Example:
#   hyku-metadata/GSE/druid_wg827ks1643/data/metadata/descMetadata.xml
data = Dir.glob("#{base_path}/**/descMetadata.xml").map do |filename|
         id = filename.gsub(%r{.*/druid_(\w+)/.*}, '\1')
         {id: [id], type: ['ETD']}.merge(Importer::ModsParser.new(filename).attributes)
       end

# Process the contributor into a flat field and drop 'notes_attributes' and 'collection'
data.each do |record|
  record[:contributor] = record[:contributor].flat_map { |c| c[:name] }
  record[:date_created] = record.delete(:created_attributes).flat_map { |c| c[:start] }
  record[:file] = [nil]
  record.delete(:notes_attributes)
  record.delete(:citation)
  record.delete(:record_origin)
  record.delete(:institution)
  record.delete(:collection) # our data doesn't have collection in it.
end

headers = data.map do |record|
  record.each_with_object({}) { |(k, v), o| o[k] = v.count }
end

uniq_headers = headers.map(&:keys).flatten.uniq

# How many columns does each field take up. Look for the widest one.
cols_for_attribute = uniq_headers.each_with_object({}) do |k, h|
  h[k] = headers.map{ |header| header[k] }.max
end

# Discard fields that aren't used.
used_fields = cols_for_attribute.select { |k, width| width > 0 || k == :file }.keys

CSV.open(output_path, "wb") do |csv|
  csv << used_fields.map { |k| Array.new(cols_for_attribute[k]) { k } }.flatten.map(&:to_s)
  data.each do |record|
    derp = used_fields.flat_map do |k|
      record[k] + Array.new(cols_for_attribute[k] - record[k].length) { nil }
    end
    csv << derp
  end
end

puts 'import complete.'
